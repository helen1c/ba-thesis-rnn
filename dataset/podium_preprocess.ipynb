{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "clinical-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "from podium import TabularDataset, Vocab, Field\n",
    "from podium.vocab import Special\n",
    "from podium.vectorizers import GloVe\n",
    "from podium import BucketIterator\n",
    "from podium.vocab import UNK, PAD, EOS, BOS\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "graphic-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_train_csv = 'dd_dataset/train/train/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "racial-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase(raw):\n",
    "    \"\"\"Lowercases the input string\"\"\"\n",
    "    return raw.lower()\n",
    "\n",
    "class RemoveBlanks:\n",
    "    def __call__(self, raw, tokenized):\n",
    "        \"\"\"Remove punctuation from tokenized data\"\"\"\n",
    "        return raw, [tok for tok in tokenized if tok not in [' ', \"\\n\", \"\\t\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "linear-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab(max_size=10000, min_freq=2, specials=(PAD(),UNK(),BOS(),EOS()))\n",
    "text = Field('text',\n",
    "             numericalizer=vocab,\n",
    "             pretokenize_hooks=[lowercase],\n",
    "             posttokenize_hooks=[RemoveBlanks()],\n",
    "             tokenizer='spacy-en_core_web_sm')\n",
    "fields = {'text': text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TabularDataset(data_path_train_csv, format='csv', fields=fields)\n",
    "dataset.finalize_fields()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "institutional-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = fields['text'].vocab\n",
    "glove = GloVe()\n",
    "embeddings = glove.load_vocab(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "appropriate-banks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For vocabulary of size: 10000 loaded embedding matrix of shape: (10000, 300)\n"
     ]
    }
   ],
   "source": [
    "print(f\"For vocabulary of size: {len(vocab)} loaded embedding matrix of shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "legal-egypt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocab({specials: ('<PAD>', '<UNK>', '<BOS>', '<EOS>'), eager: False, is_finalized: True, size: 10000})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def instance_length(instance):\n",
    "    _, tokenized = instance.text\n",
    "    return len(tokenized)\n",
    "\n",
    "bucket_iterator = BucketIterator(dataset, batch_size=32, bucket_sort_key=instance_length)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "yellow-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(batch, embeddings):\n",
    "    w2vec = np.zeros((batch.shape[0], batch.shape[1], embeddings.shape[1]))\n",
    "    for i in range(batch.shape[0]):\n",
    "        for j in range(batch.shape[1]):\n",
    "            w2vec[i,j,:] = embeddings[batch[i,j]]\n",
    "    \n",
    "    return w2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "described-gregory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 4, 300)\n"
     ]
    }
   ],
   "source": [
    "for iterator in bucket_iterator:\n",
    "    batch = iterator.text\n",
    "    print(get_embeddings(batch, embeddings).shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
