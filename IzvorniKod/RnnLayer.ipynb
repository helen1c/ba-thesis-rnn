{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "swedish-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "congressional-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(object):\n",
    "    \n",
    "    def forward(self, X_in):\n",
    "        return np.tanh(X_in)\n",
    "    \n",
    "    def backward(self, X_in, dEdY):\n",
    "        #dEdX = dEdY * dYdX = dEdY * 1 - (tanh(X))^2\n",
    "        dYdX = 1 - (np.tanh(X_in))**2\n",
    "        return dYdX * dEdY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "middle-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLu(object):\n",
    "    \n",
    "    def forward(self, X_in):\n",
    "        return np.maximum(X_in, 0)\n",
    "    \n",
    "    def backward(self, X_in, dEdY):\n",
    "        dYdX = (X_in > 0)  \n",
    "        return dYdX * dEdY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "descending-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnLayer(object):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, seq_len, batch_size, use_bias=True):\n",
    "        sq = np.sqrt(1. / hidden_dim)\n",
    "        \n",
    "        self.use_bias = use_bias\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.input_weights = np.random.uniform(-sq, sq, (hidden_dim, input_dim))\n",
    "        self.hidden_weights = np.random.uniform(-sq, sq, (hidden_dim, hidden_dim))\n",
    "        \n",
    "        if use_bias == True:\n",
    "            self.hidden_bias = np.random.uniform(-sq, sq, hidden_dim)\n",
    "            self.input_bias = np.random.uniform(-sq, sq, hidden_dim)\n",
    "        else:\n",
    "            self.hidden_bias = np.zeros((hidden_dim))\n",
    "            self.input_bias = np.zeros((hidden_dim))\n",
    "        \n",
    "    def forward(self, X_in):\n",
    "        \n",
    "        #treba li dodati provjeru je li X_in stvarno ima sekvencu jednaku seq_len?\n",
    "        #treba li dodati provjeru je li X_in prva koordinata jednaka batch_size\n",
    "        \n",
    "        #u ovom slucaju sam pretpostavio da je za sve inpute, pocetno stanje 0 u 0. vremenskom trenutku\n",
    "        H0 = np.zeros((self.hidden_dim))\n",
    "        \n",
    "        H = np.zeros((self.batch_size, self.seq_len + 1, self.hidden_dim)) \n",
    "        H[:,0,:] = H0\n",
    "        \n",
    "        tanh = Tanh()\n",
    "        \n",
    "        for i in range(self.seq_len):\n",
    "            \n",
    "            input_part = np.einsum('ij,jk->ik', X_in[:,i,:], self.input_weights.T) + self.input_bias\n",
    "            hidden_part = np.einsum('ij,jj->ij', H[:,i,:], self.hidden_weights.T) + self.hidden_bias\n",
    "            Z = input_part + hidden_part\n",
    "            \n",
    "            H[:,i+1,:] = tanh.forward(Z)\n",
    "        \n",
    "        return H, H[:,self.seq_len,:]\n",
    "            \n",
    "    def backward(self, X_in, H, dEdY):\n",
    "        #Vrijedi: S_k+1 = tanh(X_in[:,k+1,:] * W_in.T + B_in + H[:,k+1,:] * W_hh.T + B_h)\n",
    "        #dEdW_in = dEdY * dYdW_in = dEdY * (dtanh(X) * dYdW_in)\n",
    "        #dEdW_hh = dEdY * dYdW_hh...\n",
    "        \n",
    "        dEdW_in = np.zeros_like(self.input_weights)\n",
    "        dEdW_hh = np.zeros_like(self.hidden_weights)\n",
    "        \n",
    "        dEdB_in = np.zeros_like(self.input_bias)\n",
    "        dEdB_h = np.zeros_like(self.hidden_bias)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "mediterranean-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnn forward checker\n",
    "\n",
    "rnn = RnnLayer(4, 5, 3, 2)\n",
    "#input dim 4\n",
    "#hidden dim 5\n",
    "#batch 2\n",
    "#timestamps 3\n",
    "\n",
    "X_in = np.array([[[1,2,1,3],[2,2,3,1],[0,2,3,1]],[[1,3,4,3],[1,2,1,1],[1,0,1,2]]])\n",
    "H, last = rnn.forward(X_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-maine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-arcade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-stone",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
